{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\" \n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, GRU, Multiply, Reshape\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "# from tcn import TCN\n",
    "%matplotlib inline\n",
    "from keras.layers import merge, Input, Dense, TimeDistributed, Lambda                                   \n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, GlobalMaxPooling2D,MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Input, GlobalAveragePooling2D,AveragePooling2D, Add\n",
    "from keras.optimizers import Adam, rmsprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Activation, Lambda\n",
    "from keras.layers import Conv1D, SpatialDropout1D\n",
    "from keras.layers import Convolution1D, Dense\n",
    "MAX_SENT_LENGTH = 55\n",
    "MAX_SENTS = time_step\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rf_data=pd.read_csv('/home/',encoding='gb2312')\n",
    "# rf_data=rf_data.drop(rf_data.columns[7],axis=1)\n",
    "# rf_data=rf_data.drop(labels=,'columns')\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "Enc=OrdinalEncoder()\n",
    "x=Enc.fit_transform(np.array(rf_data.iloc[:,0]).reshape(-1,1))\n",
    "# id=rf_data[:,0]\n",
    "# interval1=rf_data.iloc[:,1]\n",
    "# interval2=rf_data[:,2]\n",
    "\n",
    "rf_data.insert(3,\"idco2der\",x)\n",
    "rf_data.insert (4,\"interval1\",[time.localtime(ti).tm_hour for ti in rf_data.iloc[:,1].values])\n",
    "rf_data.insert (5,\"interval2\",[time.localtime(ti).tm_hour for ti in rf_data.iloc[:,2].values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "futrue_time=1\n",
    "\n",
    "time_step=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data_train=rf_data.iloc[:400,3:]\n",
    "rf_data_test=rf_data.iloc[400: ,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 35)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chu(x):\n",
    "    x=x/100\n",
    "    return x\n",
    "def  add_df(x):\n",
    "    x = 1 + x\n",
    "    return x\n",
    "\n",
    "target_data=rf_data.iloc[:,10:11]\n",
    "for i in range(time_step-1,25):\n",
    "    target_data['整体成单数'+str(i)]=target_data['999'].shift(-i)\n",
    "# rf_data_train=rf_data_train.dropna(how='any')\n",
    "td=target_data.iloc[:,1:2]\n",
    "# td_test=target_data.iloc[376:,1:2]\n",
    "td[\"add1\"]=target_data['整体成单数'+str(time_step)].map(chu)\n",
    "# td[\"add1\"]=target_data['整体成单数'+str(time_step)]\n",
    "td[\"add1\"]=td[\"add1\"].map(add_df)\n",
    "tdt=td.iloc[:400-time_step,1:2]\n",
    "tdte=td.iloc[400:502-time_step,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "zb_data=rf_data_train\n",
    "# gg_data=rf_data_train.iloc[:,25:]\n",
    "# intera_data=rf_data_train.iloc[:,22:25]\n",
    "# rf_data_train=std.fit_transform(rf_data_train)\n",
    "# # sd=std.fit_transform(sd)\n",
    "# zb_data=rf_data_train.iloc[:,:]\n",
    "# gg_data=rf_data_train.iloc[:,:]\n",
    "# intera_data=rf_data_train.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step=24\n",
    "# gg_m=[]\n",
    "# for i in range(1,time_step+1):\n",
    "#     locals()['gg_data'+str(i)]=gg_data[i-1:400-time_step-1+i].values\n",
    "    \n",
    "#     gg_m.append(locals()['gg_data'+str(i)])\n",
    "    \n",
    "zb_m=[]\n",
    "for i in range(1,time_step+1):\n",
    "    locals()['zb_data'+str(i)]=zb_data[i-1:400-time_step-1+i].values\n",
    "    \n",
    "    zb_m.append(locals()['zb_data'+str(i)])\n",
    "# intera_m=[]\n",
    "# for i in range(1,time_step+1):\n",
    "#     locals()['intera_data'+str(i)]=intera_data[i-1:400-time_step-1+i].values\n",
    "    \n",
    "#     intera_m.append(locals()['intera_data'+str(i)])\n",
    "\n",
    "# gg_m=(np.array(gg_m).swapaxes(0,1))\n",
    "zb_m=(np.array(zb_m).swapaxes(0,1))\n",
    "# intera_m=(np.array(intera_m).swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_data_test=std.fit_transform(rf_data_test)\n",
    "# sd=std.fit_transform(sd)\n",
    "zb_data_t=rf_data_test\n",
    "# gg_data_t=rf_data_test.iloc[:,25:]\n",
    "# intera_data_t=rf_data_test.iloc[:,22:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# time_step=24\n",
    "# gg_mt=[]\n",
    "# for i in range(1,time_step+1):\n",
    "#     locals()['gg_data_t'+str(i)]=gg_data_t[i-1:102-time_step-1+i].values\n",
    "    \n",
    "#     gg_mt.append(locals()['gg_data_t'+str(i)])\n",
    "    \n",
    "zb_mt=[]\n",
    "for i in range(1,time_step+1):\n",
    "    locals()['zb_data_t'+str(i)]=zb_data_t[i-1:102-time_step-1+i].values\n",
    "    \n",
    "    zb_mt.append(locals()['zb_data_t'+str(i)])\n",
    "# intera_mt=[]\n",
    "# for i in range(1,time_step+1):\n",
    "#     locals()['intera_data_t'+str(i)]=intera_data_t[i-1:102-time_step-1+i].values\n",
    "    \n",
    "#     intera_mt.append(locals()['intera_data_t'+str(i)])\n",
    "\n",
    "# gg_mt=(np.array(gg_mt).swapaxes(0,1))\n",
    "zb_mt=(np.array(zb_mt).swapaxes(0,1))\n",
    "# intera_mt=(np.array(intera_mt).swapaxes(0,1))\n",
    "zzz_m=rf_data_train.iloc[time_step:,:].drop(rf_data_train.columns[7],axis=1)\n",
    "zzz_mt=rf_data_test.iloc[time_step:,:].drop(rf_data_test.columns[7],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_len=35\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376, 34)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz_m.shape\n",
    "from keras.layers import Lambda, Input, Dense, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "input1 = Input(shape=(zb_m.shape[1],zb_m.shape[2]))\n",
    "input2 = Input(shape=(34,))\n",
    "\n",
    "x = LSTM(units=35)(input1)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = concatenate([x, input2])\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output = Dense(1, activation='relu')(x)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "model.summary()  #打印模型\n",
    " \n",
    "model.compile(optimizer=Adam(lr=0.0005, beta_1=0.99, beta_2=0.999, decay=0.006), loss='mae')  #编译模型\n",
    "history=model.fit([zb_m,zzz_m],tdt, epochs=10000, batch_size=16,verbose=2,validation_split=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit([zb_m,zzz_m],tdt, epochs=10000, batch_size=16,verbose=2,validation_split=0.1,shuffle=True)\n",
    "# 绘制训练 & 验证的损失值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca8b9bb19742d5b6220a7434602d631e4d56cba6afd780858bcdcaed41b73f98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
